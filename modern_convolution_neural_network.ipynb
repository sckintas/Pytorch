{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4752b127",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\OWNER\\anaconda3\\lib\\site-packages\\sklearn\\datasets\\_openml.py:932: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/56000 (0%)]\tLoss: 2.307133\n",
      "Train Epoch: 1 [20000/56000 (36%)]\tLoss: 0.311907\n",
      "Train Epoch: 1 [40000/56000 (71%)]\tLoss: 0.542658\n",
      "\n",
      "Test set: Average loss: 0.0030, Accuracy: 12777/14000 (91%)\n",
      "\n",
      "Train Epoch: 2 [0/56000 (0%)]\tLoss: 0.558028\n",
      "Train Epoch: 2 [20000/56000 (36%)]\tLoss: 0.193448\n",
      "Train Epoch: 2 [40000/56000 (71%)]\tLoss: 0.124939\n",
      "\n",
      "Test set: Average loss: 0.0023, Accuracy: 13068/14000 (93%)\n",
      "\n",
      "Train Epoch: 3 [0/56000 (0%)]\tLoss: 0.250345\n",
      "Train Epoch: 3 [20000/56000 (36%)]\tLoss: 0.273818\n",
      "Train Epoch: 3 [40000/56000 (71%)]\tLoss: 0.255067\n",
      "\n",
      "Test set: Average loss: 0.0019, Accuracy: 13297/14000 (95%)\n",
      "\n",
      "Train Epoch: 4 [0/56000 (0%)]\tLoss: 0.148569\n",
      "Train Epoch: 4 [20000/56000 (36%)]\tLoss: 0.101376\n",
      "Train Epoch: 4 [40000/56000 (71%)]\tLoss: 0.131242\n",
      "\n",
      "Test set: Average loss: 0.0016, Accuracy: 13369/14000 (95%)\n",
      "\n",
      "Train Epoch: 5 [0/56000 (0%)]\tLoss: 0.070929\n",
      "Train Epoch: 5 [20000/56000 (36%)]\tLoss: 0.145691\n",
      "Train Epoch: 5 [40000/56000 (71%)]\tLoss: 0.069535\n",
      "\n",
      "Test set: Average loss: 0.0014, Accuracy: 13440/14000 (96%)\n",
      "\n",
      "Train Epoch: 6 [0/56000 (0%)]\tLoss: 0.098030\n",
      "Train Epoch: 6 [20000/56000 (36%)]\tLoss: 0.126253\n",
      "Train Epoch: 6 [40000/56000 (71%)]\tLoss: 0.085518\n",
      "\n",
      "Test set: Average loss: 0.0013, Accuracy: 13500/14000 (96%)\n",
      "\n",
      "Train Epoch: 7 [0/56000 (0%)]\tLoss: 0.094929\n",
      "Train Epoch: 7 [20000/56000 (36%)]\tLoss: 0.124007\n",
      "Train Epoch: 7 [40000/56000 (71%)]\tLoss: 0.171360\n",
      "\n",
      "Test set: Average loss: 0.0012, Accuracy: 13534/14000 (97%)\n",
      "\n",
      "Train Epoch: 8 [0/56000 (0%)]\tLoss: 0.066711\n",
      "Train Epoch: 8 [20000/56000 (36%)]\tLoss: 0.037819\n",
      "Train Epoch: 8 [40000/56000 (71%)]\tLoss: 0.062338\n",
      "\n",
      "Test set: Average loss: 0.0011, Accuracy: 13560/14000 (97%)\n",
      "\n",
      "Train Epoch: 9 [0/56000 (0%)]\tLoss: 0.096832\n",
      "Train Epoch: 9 [20000/56000 (36%)]\tLoss: 0.077831\n",
      "Train Epoch: 9 [40000/56000 (71%)]\tLoss: 0.147766\n",
      "\n",
      "Test set: Average loss: 0.0010, Accuracy: 13576/14000 (97%)\n",
      "\n",
      "Train Epoch: 10 [0/56000 (0%)]\tLoss: 0.080450\n",
      "Train Epoch: 10 [20000/56000 (36%)]\tLoss: 0.049788\n",
      "Train Epoch: 10 [40000/56000 (71%)]\tLoss: 0.055988\n",
      "\n",
      "Test set: Average loss: 0.0010, Accuracy: 13599/14000 (97%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import optim\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load and preprocess the MNIST dataset\n",
    "X, y = fetch_openml('mnist_784', version=1, return_X_y=True, as_frame=False)\n",
    "X = np.array(X).astype('float32')\n",
    "y = np.array(y).astype('int64')\n",
    "X /= 255.0\n",
    "\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = torch.from_numpy(X_train.reshape(-1, 1, 28, 28))\n",
    "y_train = torch.from_numpy(y_train)\n",
    "train_data = list(zip(X_train, y_train))\n",
    "train_dataloader = DataLoader(train_data, batch_size=100, shuffle=True)\n",
    "\n",
    "X_val = torch.from_numpy(X_val.reshape(-1, 1, 28, 28))\n",
    "y_val = torch.from_numpy(y_val)\n",
    "val_data = list(zip(X_val, y_val))\n",
    "val_dataloader = DataLoader(val_data, batch_size=100)\n",
    "\n",
    "# Define the network structure\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.fc1 = nn.Linear(26*26*32, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = x.view(-1, 26*26*32) # flatten\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        return self.fc2(x)\n",
    "\n",
    "model = Net()\n",
    "\n",
    "# Choose an optimizer and loss function\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "def train(epoch, log_interval=200):\n",
    "    model.train()\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print(f\"Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_dataloader.dataset)} ({100. * batch_idx / len(train_dataloader):.0f}%)]\\tLoss: {loss.item():.6f}\")\n",
    "\n",
    "# Define the testing function\n",
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in val_dataloader:\n",
    "            output = model(data)\n",
    "            test_loss += criterion(output, target).item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(val_dataloader.dataset)\n",
    "\n",
    "    print(f\"\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(val_dataloader.dataset)} ({100. * correct / len(val_dataloader.dataset):.0f}%)\\n\")\n",
    "\n",
    "# Execute the training/testing process\n",
    "for epoch in range(1, 11):\n",
    "    train(epoch)\n",
    "    test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac9d135",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
